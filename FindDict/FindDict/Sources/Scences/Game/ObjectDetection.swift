//
//  ObjectDetection.swift
//  FindDict
//
//  Created by ê¹€ì§€ë¯¼ on 2022/09/29.
//

import Foundation
import UIKit
import Vision
import SnapKit
import Then


class ObjectDetectionVC:ViewController {
    
    var pixelBuffer:CVPixelBuffer? = nil {
        didSet{
            setUpModel()
            print("pixelBuffer")
            handleImage(pixelBuffer: pixelBuffer)
        }
    }
    var image = UIImageView()
    let boxesView = DrawingBoundingBoxView()
    
    let objectDectectionModel = yolov5m()
    var predictions: [VNRecognizedObjectObservation] = []
    
    // MARK: - Vision Properties
    var request: VNCoreMLRequest?
    var visionModel: VNCoreMLModel?
    var isInferencing = false
    
    let semaphore = DispatchSemaphore(value: 1)
    
    // MARK: - View Life Cycle
    override func viewDidLoad() {
        super.viewDidLoad()
//        setUpModel()
        setLayout()
//        setButtonActions()
    }

    
    // MARK: - Setup Core ML
    func setUpModel() {
        
        // Vision í”„ë ˆì„ì›Œí¬ì˜ ìš”ì²­ í´ë˜ìŠ¤ì™€ í˜¸í™˜ë˜ë ¤ë©´ ë°˜ë“œì‹œ ëª¨ë¸ì„ VNCoreMLModelë¡œ ê°ì‹¸ì„œ ì¸ìŠ¤í„´ìŠ¤í™”.
        if let visionModel = try? VNCoreMLModel(for: objectDectectionModel.model) {
            
            // ëª¨ë¸ ì˜ ê°ìŒŒìœ¼ë©´ ì´ë¥¼ visionModelì— ì €ì¥.
            self.visionModel = visionModel
            
            // VNCoreMLRequest : ì…ë ¥ì´ë¯¸ì§€ë¥¼ í• ë‹¹ëœ CoreML ëª¨ë¸ì— ì „ë‹¬í•˜ê¸° ì „ì— í•„ìš”í•œ ì „ì²˜ë¦¬ ìˆ˜í–‰.
            // ì „ì²˜ë¦¬ ìˆ˜í–‰í•œ ê²°ê³¼ë¥¼ visionRequestDidCompleteê°€ ë°›ëŠ”ë‹¤.
            request = VNCoreMLRequest(model: visionModel, completionHandler: visionRequestDidComplete) //1. ìš”ì²­ ì •ì˜
            
            // .centerCropìœ¼ë¡œ í•˜ë©´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •í•˜ëŠ”ë° í•„ìš”í•œ ê²½ìš° ì´ë¯¸ì§€ ì¤‘ì•™ì„ ê¸°ì¤€ìœ¼ë¡œ ê¸´ ìª½ì„ ìë¥¸ë‹¤.
            request?.imageCropAndScaleOption = .scaleFill
        } else {
            fatalError("fail to create vision model")
        }
    }
    
    func handleImage(pixelBuffer: CVPixelBuffer?){
        if !self.isInferencing, let pixelBuffer = pixelBuffer {
            self.isInferencing = true
            print("handleImage")
            self.predictUsingVision(pixelBuffer: pixelBuffer)
        }
    }
    
    
    func predictUsingVision(pixelBuffer: CVPixelBuffer) {
        guard let request = request else { fatalError() }
        // vision framework configures the input size of image following our model's input configuration automatically
        self.semaphore.wait()
        
        //2. í•¸ë“¤ëŸ¬ ì •ì˜
        let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer)
        try? handler.perform([request])
    }
    
    // MARK: - Post-processing
    // ìš”ì²­ ì‹¤í–‰ í›„
    func visionRequestDidComplete(request: VNRequest, error: Error?) {
        
        // ê²°ê³¼ ê°€ì ¸ì˜¨ ê±¸ ì²˜ë¦¬, ë·°ì— ë³´ì—¬ì£¼ê¸°
        if let predictions = request.results as? [VNRecognizedObjectObservation] {
            print(predictions.first?.labels.first?.identifier ?? "nil")
            print(predictions.first?.labels.first?.confidence ?? -1)
//            print(predictions.)
//            print(predictions.)
            DispatchQueue.main.async {
                self.boxesView.predictedObjects = predictions
//                self.labelsTableView.reloadData()

                // end of measure
//                self.ğŸ‘¨â€ğŸ”§.ğŸ¬ğŸ¤š()
                
                self.isInferencing = false
            }
            
            self.predictions = predictions
//            self.boxesView.predictedObjects = predictions
            print(predictions)
            
        }
        self.isInferencing = false
        self.semaphore.signal()
    }
    
}
// MARK: - UI
extension ObjectDetectionVC {
    func setLayout() {
        view.addSubViews([image,boxesView])
        image.snp.makeConstraints{
            //            $0.top.equalTo(view.safeAreaLayoutGuide.snp.top).offset(17)
            //            $0.centerX.equalTo(view.safeAreaLayoutGuide)
                        $0.center.equalTo(view.safeAreaLayoutGuide)
            //            $0.leading.equalTo(view.safeAreaLayoutGuide.snp.leading).offset(60)
            //            $0.trailing.equalTo(view.safeAreaLayoutGuide.snp.trailing).offset(-60)
            //            $0.bottom.lessThanOrEqualTo(view.safeAreaLayoutGuide.snp.bottom).inset(50)
                        $0.height.equalTo(250)
                    }
        
        boxesView.snp.makeConstraints{
//            $0.top.equalTo(view.safeAreaLayoutGuide.snp.top).offset(17)
//            $0.centerX.equalTo(view.safeAreaLayoutGuide)
            $0.center.equalTo(view.safeAreaLayoutGuide)
//            $0.leading.equalTo(view.safeAreaLayoutGuide.snp.leading).offset(60)
//            $0.trailing.equalTo(view.safeAreaLayoutGuide.snp.trailing).offset(-60)
//            $0.bottom.lessThanOrEqualTo(view.safeAreaLayoutGuide.snp.bottom).inset(50)
            $0.height.equalTo(250)
        }
    }
}
